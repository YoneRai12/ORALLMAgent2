"""Main entry point for Manus-style autonomous AI agent system.

Provides CLI and REST API interfaces for sending natural language tasks to
local LLM servers.  This scaffold is designed to be extended with additional
planning, tool execution, and reflection logic.
"""
from __future__ import annotations

import argparse
import os
from typing import List

import requests
from fastapi import FastAPI
from pydantic import BaseModel
from dotenv import load_dotenv

# Load environment variables from .env if present
load_dotenv()

app = FastAPI(title="Manus Agent", description="Autonomous AI agent scaffold")


class TaskRequest(BaseModel):
    """Schema for REST API task requests."""

    instruction: str


def call_llm(prompt: str) -> str:
    """Call the configured LLM server and return the generated text.

    Parameters
    ----------
    prompt: str
        The prompt to send to the LLM.

    Returns
    -------
    str
        The text content generated by the LLM.
    """

    endpoint = os.getenv("LLM_ENDPOINT", "http://localhost:8000/v1/chat/completions")
    model = os.getenv("LLM_MODEL", "default")

    response = requests.post(
        endpoint,
        json={
            "model": model,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": int(os.getenv("LLM_MAX_TOKENS", "512")),
        },
        timeout=60,
    )
    response.raise_for_status()
    data = response.json()
    return data.get("choices", [{}])[0].get("message", {}).get("content", "")


@app.post("/api/task")
async def run_task(req: TaskRequest) -> dict:
    """Generate a plan for the provided instruction.

    This endpoint only produces a plan.  Execution of the plan and step-by-step
    reflection should be implemented in future iterations.
    """

    plan = call_llm(f"Create a plan for the following task and return JSON steps: {req.instruction}")
    return {"plan": plan}


def cli_mode(args: List[str]) -> None:
    """Run the agent in CLI mode."""

    instruction = " ".join(args) if args else input("Instruction: ")
    plan = call_llm(f"Create a plan for the following task and return JSON steps: {instruction}")
    print("Plan:\n", plan)
    # Placeholder: execute the plan step-by-step and provide reflections.
    print("Execution is not yet implemented in this scaffold.")


def main() -> None:
    """Parse command-line arguments and start CLI or REST API server."""

    parser = argparse.ArgumentParser(description="Manus-style autonomous agent")
    parser.add_argument("instruction", nargs=argparse.REMAINDER, help="Task instruction for CLI mode")
    parser.add_argument("--api", action="store_true", help="Run REST API server instead of CLI")
    args = parser.parse_args()

    if args.api:
        import uvicorn

        port = int(os.getenv("PORT", "8001"))
        # Warning: ensure the server is not exposed to the public internet.
        uvicorn.run("main:app", host="0.0.0.0", port=port, reload=False)
    else:
        cli_mode(args.instruction)


if __name__ == "__main__":
    main()
